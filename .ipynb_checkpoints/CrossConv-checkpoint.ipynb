{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "c013e55c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from einops import rearrange\n",
    "from einops.layers.torch import Rearrange\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "b1cc6cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_3x3_bn(inp, oup, image_size, downsample=False):\n",
    "    stride = 1 if downsample == False else 2\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(inp, oup, 3, stride, 1, bias=False),\n",
    "        nn.BatchNorm2d(oup),\n",
    "        nn.GELU()\n",
    "    )\n",
    "class PreNorm(nn.Module):\n",
    "    def __init__(self, dim, fn, norm):\n",
    "        super().__init__()\n",
    "        self.norm = norm(dim)\n",
    "        self.fn = fn\n",
    "\n",
    "    def forward(self, x, **kwargs):\n",
    "        return self.fn(self.norm(x), **kwargs)\n",
    "\n",
    "# PreNorm(inp, self.attn, nn.LayerNorm)\n",
    "\n",
    "class SE(nn.Module):\n",
    "    def __init__(self, inp, oup, expansion=0.25):\n",
    "        super().__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(oup, int(inp * expansion), bias=False),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(int(inp * expansion), oup, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, c, _, _ = x.size()\n",
    "        y = self.avg_pool(x).view(b, c)\n",
    "        y = self.fc(y).view(b, c, 1, 1)\n",
    "        return x * y\n",
    "\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, dim, hidden_dim, dropout=0.):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(dim, hidden_dim),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim, dim),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "\n",
    "class MBConv(nn.Module):\n",
    "    def __init__(self, inp, oup, image_size, downsample=False, expansion=4):\n",
    "        super().__init__()\n",
    "        self.downsample = downsample\n",
    "        stride = 1 if self.downsample == False else 2\n",
    "        hidden_dim = int(inp * expansion)\n",
    "\n",
    "        if self.downsample:\n",
    "            self.pool = nn.MaxPool2d(3, 2, 1)\n",
    "            self.proj = nn.Conv2d(inp, oup, 1, 1, 0, bias=False)\n",
    "\n",
    "        if expansion == 1:\n",
    "            self.conv = nn.Sequential(\n",
    "                # dw\n",
    "                nn.Conv2d(hidden_dim, hidden_dim, 3, stride,\n",
    "                          1, groups=hidden_dim, bias=False),\n",
    "                nn.BatchNorm2d(hidden_dim),\n",
    "                nn.GELU(),\n",
    "                # pw-linear\n",
    "                nn.Conv2d(hidden_dim, oup, 1, 1, 0, bias=False),\n",
    "                nn.BatchNorm2d(oup),\n",
    "            )\n",
    "        else:\n",
    "            self.conv = nn.Sequential(\n",
    "                # pw\n",
    "                # down-sample in the first conv\n",
    "                nn.Conv2d(inp, hidden_dim, 1, stride, 0, bias=False),\n",
    "                nn.BatchNorm2d(hidden_dim),\n",
    "                nn.GELU(),\n",
    "                # dw\n",
    "                nn.Conv2d(hidden_dim, hidden_dim, 3, 1, 1,\n",
    "                          groups=hidden_dim, bias=False),\n",
    "                nn.BatchNorm2d(hidden_dim),\n",
    "                nn.GELU(),\n",
    "                SE(inp, hidden_dim),\n",
    "                # pw-linear\n",
    "                nn.Conv2d(hidden_dim, oup, 1, 1, 0, bias=False),\n",
    "                nn.BatchNorm2d(oup),\n",
    "            )\n",
    "        \n",
    "        self.conv = PreNorm(inp, self.conv, nn.BatchNorm2d)\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.downsample:\n",
    "            return self.proj(self.pool(x)) + self.conv(x)\n",
    "        else:\n",
    "            return x + self.conv(x)\n",
    "\n",
    "\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, inp, oup, image_size, heads=8, dim_head=32, dropout=0.):\n",
    "        super().__init__()\n",
    "        inner_dim = dim_head * heads\n",
    "        project_out = not (heads == 1 and dim_head == inp)\n",
    "\n",
    "        self.ih, self.iw = image_size\n",
    "\n",
    "        self.heads = heads\n",
    "        self.scale = dim_head ** -0.5\n",
    "\n",
    "        # parameter table of relative position bias\n",
    "        self.relative_bias_table = nn.Parameter(\n",
    "            torch.zeros((2 * self.ih - 1) * (2 * self.iw - 1), heads))\n",
    "\n",
    "        coords = torch.meshgrid((torch.arange(self.ih), torch.arange(self.iw)))\n",
    "        coords = torch.flatten(torch.stack(coords), 1)\n",
    "        relative_coords = coords[:, :, None] - coords[:, None, :]\n",
    "\n",
    "        relative_coords[0] += self.ih - 1\n",
    "        relative_coords[1] += self.iw - 1\n",
    "        relative_coords[0] *= 2 * self.iw - 1\n",
    "        relative_coords = rearrange(relative_coords, 'c h w -> h w c')\n",
    "        relative_index = relative_coords.sum(-1).flatten().unsqueeze(1)\n",
    "        self.register_buffer(\"relative_index\", relative_index)\n",
    "\n",
    "        self.attend = nn.Softmax(dim=-1)\n",
    "        self.to_qkv = nn.Linear(inp, inner_dim * 3, bias=False)\n",
    "\n",
    "        self.to_out = nn.Sequential(\n",
    "            nn.Linear(inner_dim, oup),\n",
    "            nn.Dropout(dropout)\n",
    "        ) if project_out else nn.Identity()\n",
    "\n",
    "    def forward(self, x):\n",
    "        qkv = self.to_qkv(x).chunk(3, dim=-1)\n",
    "        q, k, v = map(lambda t: rearrange(\n",
    "            t, 'b n (h d) -> b h n d', h=self.heads), qkv)\n",
    "        dots = torch.matmul(q, k.transpose(-1, -2)) * self.scale\n",
    "\n",
    "        # Use \"gather\" for more efficiency on GPUs\n",
    "        relative_bias = self.relative_bias_table.gather(\n",
    "            0, self.relative_index.repeat(1, self.heads))\n",
    "        relative_bias = rearrange(\n",
    "            relative_bias, '(h w) c -> 1 c h w', h=self.ih*self.iw, w=self.ih*self.iw)\n",
    "        dots = dots + relative_bias\n",
    "\n",
    "        attn = self.attend(dots)\n",
    "        out = torch.matmul(attn, v)\n",
    "        out = rearrange(out, 'b h n d -> b n (h d)')\n",
    "        out = self.to_out(out)\n",
    "        return out\n",
    "\n",
    "class Transformer(nn.Module):\n",
    "    def __init__(self, inp, oup, image_size, heads=8, dim_head=32, downsample=False, dropout=0.):\n",
    "        super().__init__()\n",
    "        hidden_dim = int(inp * 4)\n",
    "        self.ih, self.iw = image_size\n",
    "        self.downsample = downsample\n",
    "\n",
    "        if self.downsample:\n",
    "            self.pool1 = nn.MaxPool2d(3, 2, 1)\n",
    "            self.pool2 = nn.MaxPool2d(3, 2, 1)\n",
    "            self.proj = nn.Conv2d(inp, oup, 1, 1, 0, bias=False)\n",
    "\n",
    "        self.attn = Attention(inp, oup, image_size, heads, dim_head, dropout)\n",
    "        self.ff = FeedForward(oup, hidden_dim, dropout)\n",
    "\n",
    "        self.attn = nn.Sequential(\n",
    "            Rearrange('b c ih iw -> b (ih iw) c'),\n",
    "            PreNorm(inp, self.attn, nn.LayerNorm),\n",
    "            Rearrange('b (ih iw) c -> b c ih iw', ih=self.ih, iw=self.iw)\n",
    "        )\n",
    "\n",
    "        self.ff = nn.Sequential(\n",
    "            Rearrange('b c ih iw -> b (ih iw) c'),\n",
    "            PreNorm(oup, self.ff, nn.LayerNorm),\n",
    "            Rearrange('b (ih iw) c -> b c ih iw', ih=self.ih, iw=self.iw)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.downsample:\n",
    "            x = self.proj(self.pool1(x)) + self.attn(self.pool2(x))\n",
    "        else:\n",
    "            x = x + self.attn(x)\n",
    "        x = x + self.ff(x)\n",
    "        return x\n",
    "\n",
    "    \n",
    "class TransformerAlt(nn.Module):\n",
    "    def __init__(self, inp, oup, image_size, heads=8, dim_head=32, downsample=False, dropout=0.):\n",
    "        super().__init__()\n",
    "        hidden_dim = int(inp * 4)\n",
    "        self.ih, self.iw = image_size\n",
    "        self.downsample = downsample\n",
    "\n",
    "        if self.downsample:\n",
    "            self.pool1 = nn.MaxPool2d(3, 2, 1)\n",
    "            self.pool2 = nn.MaxPool2d(3, 2, 1)\n",
    "            self.proj = nn.Conv2d(inp, oup, 1, 1, 0, bias=False)\n",
    "\n",
    "        self.attn = Attention(inp, oup, image_size, heads, dim_head, dropout)\n",
    "        self.ff = FeedForward(oup, hidden_dim, dropout)\n",
    "        \n",
    "        self.pre_attn = Rearrange('b c ih iw -> b (ih iw) c')\n",
    "        self.attn = nn.Sequential(\n",
    "            PreNorm(inp, self.attn, nn.LayerNorm)\n",
    "        )\n",
    "        self.post_attn = Rearrange('b (ih iw) c -> b c ih iw', ih=self.ih, iw=self.iw)\n",
    "\n",
    "        self.ff = nn.Sequential(\n",
    "            Rearrange('b c ih iw -> b (ih iw) c'),\n",
    "            PreNorm(oup, self.ff, nn.LayerNorm),\n",
    "            Rearrange('b (ih iw) c -> b c ih iw', ih=self.ih, iw=self.iw)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.downsample:\n",
    "            tmp = self.attn(self.pre_attn(self.pool2(x)))\n",
    "            print(tmp.shape)\n",
    "            x = self.proj(self.pool1(x)) + self.post_attn(tmp)\n",
    "        else:\n",
    "            x = x + self.post_attn(self.attn(self.pre_attn(x)))\n",
    "        x = x + self.ff(x)\n",
    "        return x\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "16d1285d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.rand(1, 128, 112, 112)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "964fb293",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 12544, 128])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.view(x.shape[0], -1, x.shape[1]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "4bc0fae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrossConv(pl.LightningModule):\n",
    "    def __init__(self, image_size, in_channels, num_blocks, channels, num_classes=100):\n",
    "        super().__init__()\n",
    "        ih, iw = image_size\n",
    "        block = {'C': MBConv, 'T': Transformer}\n",
    "\n",
    "        self.s0 = self._make_layer(\n",
    "            conv_3x3_bn, in_channels, channels[0], num_blocks[0], (ih // 2, iw // 2))\n",
    "        \n",
    "        self.s1_c = self._make_layer(\n",
    "            MBConv, channels[0], channels[1], num_blocks[1], (ih // 4, iw // 4))\n",
    "        self.s1_a = self._make_layer(\n",
    "            Transformer, channels[0], channels[1], num_blocks[1], (ih // 4, iw // 4))\n",
    "        \n",
    "        self.s2_c = self._make_layer(\n",
    "            MBConv, channels[1], channels[2], num_blocks[2], (ih // 8, iw // 8))\n",
    "        self.s2_a = self._make_layer(\n",
    "            Transformer, channels[1], channels[2], num_blocks[2], (ih // 8, iw // 8))\n",
    "            \n",
    "        self.s3_c = self._make_layer(\n",
    "            MBConv, channels[2], channels[3], num_blocks[3], (ih // 16, iw // 16))\n",
    "        self.s3_a = self._make_layer(\n",
    "            Transformer, channels[2], channels[3], num_blocks[3], (ih // 16, iw // 16))\n",
    "        \n",
    "        self.s4_c = self._make_layer(\n",
    "            MBConv, channels[3], channels[4], num_blocks[4], (ih // 32, iw // 32))\n",
    "        self.s4_a = self._make_layer(\n",
    "            Transformer, channels[3], channels[4], num_blocks[4], (ih // 32, iw // 32))\n",
    "\n",
    "        self.pool = nn.AvgPool2d(ih // 32, 1)\n",
    "        self.fc = nn.Linear(channels[-1], num_classes, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.s0(x)\n",
    "        print(\"IN:\", x.shape)\n",
    "        x_c = self.s1_c(x)\n",
    "        x_a = self.s1_a(x)\n",
    "        print(\"OUTC: \", x_c.shape)\n",
    "        print(\"OUTA: \", x_a.shape)\n",
    "        # send x_c to x_a\n",
    "        x_a += x_c\n",
    "        \n",
    "        x_c = self.s2_c(x_c)\n",
    "        x_a = self.s2_a(x_a)\n",
    "        \n",
    "        x_a += x_c\n",
    "        \n",
    "        x_c = self.s3_c(x_c)\n",
    "        x_a = self.s3_a(x_a)\n",
    "        \n",
    "        x_a += x_c\n",
    "        \n",
    "        x_c = self.s4_c(x_c)\n",
    "        x_a = self.s4_a(x_a)\n",
    "        \n",
    "        x_a += x_c\n",
    "\n",
    "        x = self.pool(x_a).view(-1, x_a.shape[1])\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "    def _make_layer(self, block, inp, oup, depth, image_size):\n",
    "        layers = nn.ModuleList([])\n",
    "        for i in range(depth):\n",
    "            if i == 0:\n",
    "                layers.append(block(inp, oup, image_size, downsample=True))\n",
    "            else:\n",
    "                layers.append(block(oup, oup, image_size))\n",
    "        return nn.Sequential(*layers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "96315576",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CrossConv((224,224), 3, [2,2,3,5,2], [64,96, 192, 384, 768]).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "93622ce3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IN: torch.Size([1, 64, 112, 112])\n",
      "OUTC:  torch.Size([1, 96, 56, 56])\n",
      "OUTA:  torch.Size([1, 96, 56, 56])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.8699e-01,  1.8376e-01,  6.4260e-02,  4.9565e-01,  2.0549e-01,\n",
       "          6.4272e-01, -1.1592e+00,  8.1238e-01,  9.9985e-02, -3.1417e-01,\n",
       "          4.7120e-01,  7.2618e-01,  7.3724e-01,  3.0669e-01,  3.3929e-01,\n",
       "          2.6543e-01, -6.0442e-01,  6.6925e-01, -1.5300e-01,  3.1523e-01,\n",
       "          4.0570e-01, -4.7409e-01,  3.8161e-01, -2.1652e-02,  4.4554e-01,\n",
       "         -4.4789e-01, -7.5438e-03,  3.1133e-01, -2.1799e-01, -1.5996e+00,\n",
       "         -1.0367e+00, -3.4649e-01,  5.1882e-01, -5.7754e-02, -1.3137e-01,\n",
       "         -1.3219e-01,  3.8770e-01,  9.3633e-01,  1.5024e-01,  4.4008e-01,\n",
       "          7.0525e-02,  4.0046e-01, -1.9880e-02, -2.7394e-01,  3.9517e-01,\n",
       "          2.9172e-01, -3.2222e-01,  3.5538e-01, -1.5972e-01, -5.8321e-01,\n",
       "         -6.7887e-01,  1.9498e-01, -7.2924e-01,  2.6174e-01,  4.1293e-02,\n",
       "         -2.6217e-01,  3.0124e-01, -8.2174e-01,  1.2576e-01,  1.2329e+00,\n",
       "          8.3843e-01, -2.1704e-01,  2.6598e-01,  7.0405e-01,  1.7839e-01,\n",
       "         -3.5959e-01, -4.2120e-01, -1.4383e+00,  6.6450e-02, -6.6847e-02,\n",
       "         -2.3652e-01,  9.4235e-02, -5.6454e-01,  1.5837e-01,  6.3185e-01,\n",
       "          7.8898e-01,  2.6154e-01, -8.7954e-01, -6.0224e-02,  2.5270e-01,\n",
       "          6.9204e-01, -2.0531e-01, -8.8627e-01, -8.5526e-01, -1.7203e-01,\n",
       "          2.5891e-01, -9.6762e-01,  5.3659e-04,  1.0414e+00,  4.5825e-02,\n",
       "         -2.5168e-01,  1.0549e+00,  9.4627e-01,  5.0198e-02,  5.2132e-01,\n",
       "         -7.2804e-01,  2.8762e-01,  6.1258e-01, -5.0815e-02,  1.7904e-01]],\n",
       "       device='cuda:0', grad_fn=<MmBackward0>)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(torch.rand(1,3,224,224).cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a7fbf72",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
